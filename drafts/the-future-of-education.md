---
title: "On the future of education"
pubDatetime: 2024-01-23T03:05:18Z
excerpt: "The future is now."
---


I've [~900 words on LLMs before](https://thatxliner.github.io/blog/posts/my-thoughts-on-gpt-copyright/), albeit written quite badly and unclear. But I would to try to bring my thoughts to the open web again.

Specifically, I'm going to address my thoughts on LLMs on their effect on the education system. Ok that's a little too broad and formal, which isn't my style. Let me get to the point: I think English teachers, instead of trying to restrict AI, should actually embrace it. Fully embrace it. And that point isn't specific to English teachers as well. But once I get my point across with language teachers, I should be able to generalize this argument to any educator. Proof by induction.

Now, as a student, my described experience or how I perceive what's being taught may differ from the intended lesson; that is not my problem but an issue with how I was taught. I believe that I am a good student, a high achiever with the grades and test scores to back it up. I haven't taken any nation-wide standardized tests so far, only NWEA, but that doesn't matter. The point is, the what I believe the reasoning behind some of the things we do in the classroom context are may differ from what the intended lesson is.

Last time I checked, AI checkers were terrible. But now they seem to be in a much better state than before, at least GPTZero is. The problem I have is with the sole nature of these tools. As a student, I do not want my integrity, credibility, or grade being at the mercy of some unknown algorithm. GPTZero themselves also states that AI checkers should not be the sole deciding factor, and the ideas it mentions to "reduce the risk of AI misuse" are [similar to the ideas I have](https://gptzero.me/faq), which I will be going over later.

## The most obvious concern first

> If we allow them to use AI, how will students learn how to write properly?

In elementary, basic English syntax and grammar will be taught. The fundamentals remain unchanged. Kids that age should not have such open access to the internet anyway. Their parents should know not to let them get an OpenAI account (which requires a phone number last time I checked) and thus access to ChatGPT. Similar story goes for Google Bard. On that note, if a kid figures out how to download and run a powerful enough LLM locally, then they pretty much deserve it.

In middle school, at least in my experience, teachers teach more in depth about grammar and syntax. The actual writing is quite simple as you just need to follow some N-paragraph essay format where each paragraph is structured as Y. Obviously, AI can easily be used to generate such essays. Where AI cannot be used in is the researching. While AI can help with the research process, the chances for hallucination is high, unless its answers are based on a search engine's results. At that point, it has become an automated tool for helping with research, which is pretty useful and can benefit humanity as a whole. But for other cases such as interpretation of a book or relating it to the students' own experiences, the student will still need to read books in order to write a book report (bonus points if the teacher requires quotes from the book).

Students will need to learn how to communicate clearly to an AI, so that it writes the right things. Learning to say precisely what you want to say in the most concise way possible *is* good, efficient, and effective communication, which should be a topic taught in the regular curriculum. Despite this, the students will still need to learn how to edit and revise their essays because AI can, [and will](https://en.wikipedia.org/wiki/Murphy%27s_law), make errors. This step in the process will be why students will not be able to rely solely on an LLM, assuming high standards and integrity.

I believe that requiring students to show their work/writing process (similar to math) is still crucial. The writing process may include how they did research (which AI can help in, but in the end they'll still need to quote and cite credible sources), how they structured the essay, etc.

Assignments where students shouldn't be using AI should be designed so that students fundamentally cannot use AI on it.

Instead of trying to restrict students from using AI models to generate their essays, English teacher should actually teach them how to do so. If the essay prompt is so tedious and easily written that it could be written by an AI, then why bother with writing it? Real, influential literature is impossible to be generated by an AI. AIs can't generate new research papers. AIs cannot capture the artistic beauty that we humans can make. ~~Although it can mimic it, there has to be explicit meaning put into every word which an AI can't do~~ We should be writing new ideas, exploring novel thoughts. AIs can help with summarizing or aggregating research or history, but they can never replace the personal experiences and thoughts of a human life. If English teachers want to develop writing skills, they should make you write about yourself or topics that AIs can't write about. They shouldn't need to place any restrictions on how a student writes an essay, except for plagiarism (obviously).



Another thing about AI, AI checkers, and education as a whole is that this whole argument could also be fought on a more philosophical level. Assuming higher maturity (say a high school or college level), it is the students' responsibly to decide if they truly want to learn or not.
